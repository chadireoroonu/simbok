import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
from datetime import datetime, timedelta
import re
import os
from google import genai
from dotenv import load_dotenv

load_dotenv()
DEFAULT_API_KEY = os.getenv("GOOGLE_API_KEY", "")

st.set_page_config(page_title="ë‰´ìŠ¤ ì •ë¦¬ë´‡", page_icon="ğŸ› ï¸")

# API í‚¤ í…ŒìŠ¤íŠ¸
def test_api_key(api_key):
    try:
        client = genai.Client(api_key=api_key)
        response = client.models.generate_content(
            model="gemini-2.0-flash",
            contents="ì•ˆë…•"
        )
        if response.text:
            return True, "âœ… ì—°ê²° ì„±ê³µ!"
    except Exception as e:
        return False, f"âŒ ì—°ê²° ì‹¤íŒ¨! ì—ëŸ¬: {e}"

# AI ê°€ê³µ í•¨ìˆ˜
def generate_narration(api_key, text):
    try:
        client = genai.Client(api_key=api_key)
        prompt = f"ì•„ë˜ ë‰´ìŠ¤ë¥¼ 10ë¬¸ì¥ ì´ë‚´ì˜ êµ¬ì–´ì²´ë¡œ ìš”ì•½í•´ì¤˜:\n{text[:6000]}"
        response = client.models.generate_content(
            model="gemini-2.0-flash",
            contents=prompt
        )
        return response.text
    except Exception as e:
        return f"AI ê°€ê³µ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}"

# UI ë ˆì´ì•„ì›ƒ
st.title("ğŸ¦ ë‰´ìŠ¤ ìš”ì•½ê¸°")

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ğŸ” ê²€ìƒ‰ ì„¤ì •")
    keyword = st.text_input("í‚¤ì›Œë“œ", value="ì‹¬ë³µ")
    max_pages = st.number_input("ìˆ˜ì§‘ í˜ì´ì§€ ìˆ˜", min_value=1, max_value=20, value=5)
    st.divider()
    st.subheader("ğŸ”‘ AI ì„¤ì •")

    user_api_key = st.text_input(
        "Google API Key",
        type="password",
        value=DEFAULT_API_KEY,
        placeholder="API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš” ğŸ—ï¸"
    )
    target_api_key = user_api_key if user_api_key else DEFAULT_API_KEY

    if st.button("ğŸ”Œ API ì—°ê²° í…ŒìŠ¤íŠ¸"):
        if not target_api_key:
            st.error("API í‚¤ê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        else:
            with st.spinner("ì—°ê²° í™•ì¸ ì¤‘..."):
                success, message = test_api_key(target_api_key)
                if success:
                    st.success(message)
                else:
                    st.error(message)

    if user_api_key == DEFAULT_API_KEY and DEFAULT_API_KEY:
        st.caption("âœ… ì‹œìŠ¤í…œ(.env) API í‚¤ ë¡œë“œë¨")
    elif user_api_key:
        st.caption("âœ… ì‚¬ìš©ì ì…ë ¥ API í‚¤ ì‚¬ìš© ì¤‘")

    st.divider()
    st.subheader("ğŸ“… ì¡°íšŒ ê¸°ê°„ ì„¤ì •")
    today = datetime.now()
    seven_days_ago = today - timedelta(days=7)
    date_range = st.date_input("ì¡°íšŒ ì‹œì‘ì¼ - ì¢…ë£Œì¼", value=(seven_days_ago, today), max_value=today)

# ë‰´ìŠ¤ í¬ë¡¤ë§
def crawl_news(keyword, pages):
    article_list = []
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"}
    for page in range(1, pages + 1):
        url = f"https://search.daum.net/search?w=news&q={keyword}&p={page}&f=sort&sort=rec"
        try:
            response = requests.get(url, headers=headers, timeout=5)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            news_items = soup.find_all('li', {'data-docid': True}) or soup.select("ul.c-list-basic > li")
            for item in news_items:
                title_tag = item.select_one("div.item-title strong.tit-g a") or item.select_one("a.el-title")
                title = title_tag.get_text(strip=True) if title_tag else ""
                link = title_tag['href'] if title_tag else ""
                press_tag = item.select_one("span.txt_info") or item.select_one("span.el-info")
                press = press_tag.get_text(strip=True) if press_tag else "ì–¸ë¡ ì‚¬"
                summary_tag = item.select_one("p.conts-desc") or item.select_one("div.el-desc")
                summary = summary_tag.get_text(strip=True) if summary_tag else "ìš”ì•½ ì—†ìŒ"
                date_text_tag = item.select_one("span.gem-subinfo span.txt_info")
                date_text = date_text_tag.get_text(strip=True) if date_text_tag else "ë‚ ì§œë¶ˆëª…"
                date_obj = None
                if date_text != "ë‚ ì§œë¶ˆëª…":
                    now = datetime.now()
                    if re.match(r'\d{4}\.\d{2}\.\d{2}', date_text):
                        date_obj = datetime.strptime(date_text[:10], '%Y.%m.%d')
                    else:
                        try:
                            if "ë¶„ì „" in date_text:
                                minutes = int(re.search(r'(\d+)', date_text).group(1))
                                date_obj = now - timedelta(minutes=minutes)
                            elif "ì‹œê°„ì „" in date_text:
                                hours = int(re.search(r'(\d+)', date_text).group(1))
                                date_obj = now - timedelta(hours=hours)
                            elif "ì–´ì œ" in date_text:
                                date_obj = now - timedelta(days=1)
                        except: date_obj = None
                final_date = date_obj.strftime('%Y.%m.%d') if date_obj else "ë‚ ì§œë¶ˆëª…"
                article_list.append({"title": title, "press": press, "summary": summary, "link": link, "date": final_date, "date_obj": date_obj})
        except Exception as e:
            st.error(f"í˜ì´ì§€ {page} ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
            continue

    return article_list

# ìƒì„¸ ë‚´ìš© í¬ë¡¤ë§
def get_full_content(url):
    try:
        headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"}
        res = requests.get(url, headers=headers, timeout=5)
        soup = BeautifulSoup(res.text, 'html.parser')
        content_area = soup.select_one('section[dmcf-sid]') or soup.select_one('.article_view') or soup.select_one('#harmonyContainer') or soup.select_one('article')
        if content_area:
            paragraphs = content_area.find_all(['p', 'br'])
            text_lines = [p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True)]
            return "\n\n".join(text_lines)
        return "ë³¸ë¬¸ ì˜ì—­ì°¾ê¸°ì— ì‹¤íŒ¨í–ˆì–´ìš” ğŸ”—"
    except Exception as e:
        return f"ë³¸ë¬¸ ë¶ˆëŸ¬ì˜¤ê¸° ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}"

if 'filtered_df' not in st.session_state:
    st.session_state['filtered_df'] = None
if 'expanded_idx' not in st.session_state:
    st.session_state['expanded_idx'] = None

if st.button("ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘! ğŸš€"):
    if len(date_range) != 2:
        st.warning("ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”!")
    else:
        start_date, end_date = date_range
        start_dt = datetime.combine(start_date, datetime.min.time())
        end_dt = datetime.combine(end_date, datetime.max.time())
        with st.spinner('ë‰´ìŠ¤ë¥¼ ê¸ì–´ì˜¤ëŠ” ì¤‘...'):
            all_data = crawl_news(keyword, max_pages)
            if all_data:
                filtered_data = [a for a in all_data if a['date_obj'] and start_dt <= a['date_obj'] <= end_dt]
                if filtered_data:
                    st.session_state['filtered_df'] = pd.DataFrame(filtered_data).drop_duplicates(subset=['title'])
                else:
                    st.warning("í•´ë‹¹ ë²”ìœ„ì— ë‰´ìŠ¤ê°€ ì—†ì–´ìš” ğŸ˜¢")
            else:
                st.error("ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨!")

if st.session_state['filtered_df'] is not None:
    df = st.session_state['filtered_df']
    st.success(f"ì´ {len(df)}ê°œì˜ ê³ ìœ  ê¸°ì‚¬ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤! ğŸ‰")
    for idx, row in df.iterrows():
        is_expanded = (st.session_state['expanded_idx'] == idx)
        with st.expander(f"[{row['date']}] [{row['press']}] - {row['title']}", expanded=is_expanded):
            st.write(row['summary'])
            if st.button("ìƒì„¸ ë‚´ìš© ì „ì²´ ë³´ê¸° ğŸ“–", key=f"btn_{idx}"):
                st.session_state['expanded_idx'] = idx
                with st.spinner('ë³¸ë¬¸ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘...'):
                    st.session_state[f'content_{idx}'] = get_full_content(row['link'])
                st.rerun()
            if f'content_{idx}' in st.session_state and is_expanded:
                st.markdown("---")
                st.info(st.session_state[f'content_{idx}'])
                st.subheader("ğŸ™ï¸ AI ë‚˜ë ˆì´ì…˜ ê°€ê³µ")
                if st.button("AI ë‚˜ë ˆì´ì…˜ ìƒì„± ì‹œì‘! âœ¨", key=f"ai_{idx}"):
                    if not target_api_key:
                        st.warning("ì‚¬ì´ë“œë°”ì— API í‚¤ë¥¼ ë„£ì–´ì£¼ì„¸ìš”! ğŸ”‘")
                    else:
                        with st.spinner('Gemini AIê°€ ê°€ê³µí•˜ëŠ” ì¤‘...'):
                            narration = generate_narration(target_api_key, st.session_state[f'content_{idx}'])
                            st.session_state[f'narration_{idx}'] = narration
                        st.rerun()
                if f'narration_{idx}' in st.session_state:
                    st.write(st.session_state[f'narration_{idx}'])
            st.write(f"ğŸ”— [ì›ë¬¸ ë§í¬ ë°”ë¡œê°€ê¸°]({row['link']})")